#!/usr/bin/env python3
"""
å°è©±å¼ UI çµ„ä»¶æ¨¡çµ„
å¯¦ä½œæ‰€æœ‰å°è©±å¼ä»‹é¢çš„ UI æ¸²æŸ“å‡½æ•¸
"""

import streamlit as st
import time
import logging
from typing import Dict, Any, List, Optional, Callable

from conversation_types import Message, MessageRole, MessageType, ConversationSession, create_new_session
from conversation_flow import ConversationFlow

logger = logging.getLogger(__name__)


def add_chat_css():
    """æ·»åŠ å°è©±å¼ UI çš„è‡ªè¨‚ CSS æ¨£å¼"""
    st.markdown("""
    <style>
    /* è¨Šæ¯å¡ç‰‡æ¨£å¼ */
    .stChatMessage {
        border-radius: 12px;
        margin-bottom: 12px;
        padding: 12px 16px;
    }

    /* åˆ†æçµæœå¡ç‰‡æ¨£å¼ */
    .analysis-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 16px;
        padding: 24px;
        margin: 16px 0;
        color: white;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }

    /* å„ªåŒ–çµæœå¡ç‰‡æ¨£å¼ */
    .optimization-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        border-radius: 16px;
        padding: 24px;
        margin: 16px 0;
        box-shadow: 0 4px 12px rgba(79, 172, 254, 0.4);
    }

    /* Metric å¡ç‰‡æ¨£å¼ - ä¿æŒé è¨­é¡è‰²ä»¥ç›¸å®¹ light/dark ä¸»é¡Œ */
    div[data-testid="stMetric"] {
        background: rgba(102, 126, 234, 0.08);
        border-radius: 8px;
        padding: 12px;
        border: 1px solid rgba(102, 126, 234, 0.2);
    }

    div[data-testid="stMetric"] [data-testid="stMetricValue"] {
        font-size: 24px;
        font-weight: 600;
    }

    /* å°è©±å®¹å™¨èª¿æ•´ */
    .main .block-container {
        padding-bottom: 120px;
    }

    /* å›ºå®šåº•éƒ¨è¼¸å…¥æ¡†æ¨£å¼ */
    div[data-testid="stChatInput"] {
        position: sticky;
        bottom: 0;
        background: var(--secondary-background-color);
        padding: 16px 0;
        z-index: 100;
    }
    </style>
    """, unsafe_allow_html=True)


def render_conversation_ui(t_func: Callable[[str], str], create_llm_func: Callable[[], Any]):
    """
    æ¸²æŸ“å°è©±å¼ UI ä¸»ä»‹é¢ï¼ˆç°¡åŒ–ç‰ˆï¼šå–®æ¬¡å„ªåŒ–æµç¨‹ï¼‰

    Args:
        t_func: ç¿»è­¯å‡½æ•¸
        create_llm_func: å‰µå»º LLM å¯¦ä¾‹çš„å‡½æ•¸
    """
    session = st.session_state.current_session

    # æ·»åŠ  CSS æ¨£å¼
    add_chat_css()

    # é¡¯ç¤ºå°è©±æ­·å²
    for msg in session.messages:
        render_message(msg, t_func)

    # æ ¹æ“šç‹€æ…‹æ¸²æŸ“è¼¸å…¥å€åŸŸï¼ˆç°¡åŒ–ï¼šç„¡è¿½åŠ å°è©±ï¼‰
    render_input_area_simple(session, t_func, create_llm_func)



def render_message(msg: Message, t_func: Callable[[str], str]):
    """
    æ¸²æŸ“å–®å€‹è¨Šæ¯

    Args:
        msg: è¨Šæ¯ç‰©ä»¶
        t_func: ç¿»è­¯å‡½æ•¸
    """
    if msg.role == MessageRole.USER:
        # ç”¨æˆ¶è¨Šæ¯
        with st.chat_message("user", avatar="ğŸ§‘"):
            st.write(msg.content)

    elif msg.role == MessageRole.ASSISTANT:
        # AI è¨Šæ¯ - æ ¹æ“šé¡å‹æ¸²æŸ“ä¸åŒçµ„ä»¶
        if msg.type == MessageType.ANALYSIS:
            render_analysis_card(msg, t_func)
        elif msg.type == MessageType.QUESTIONS:
            render_questions_card(msg, t_func)
        elif msg.type == MessageType.OPTIMIZATION:
            render_optimization_card(msg, t_func)
        else:
            # ä¸€èˆ¬æ–‡å­—è¨Šæ¯
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.write(msg.content)


def render_analysis_card(msg: Message, t_func: Callable[[str], str]):
    """
    æ¸²æŸ“åˆ†æçµæœå¡ç‰‡

    Args:
        msg: åˆ†æè¨Šæ¯ç‰©ä»¶
        t_func: ç¿»è­¯å‡½æ•¸
    """
    with st.chat_message("assistant", avatar="ğŸ“Š"):
        st.markdown("#### " + t_func("analysis_result"))

        if msg.analysis_data:
            analysis = msg.analysis_data

            # è©•åˆ†å±•ç¤ºï¼ˆä½¿ç”¨ 4 æ¬„ï¼‰
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    t_func("completeness_label"),
                    f"{analysis.get('completeness_score', 0)}/10"
                )
            with col2:
                st.metric(
                    t_func("clarity_label"),
                    f"{analysis.get('clarity_score', 0)}/10"
                )
            with col3:
                st.metric(
                    t_func("structure_label"),
                    f"{analysis.get('structure_score', 0)}/10"
                )
            with col4:
                st.metric(
                    t_func("specificity_label"),
                    f"{analysis.get('specificity_score', 0)}/10"
                )

            # æç¤ºé¡å‹å’Œè¤‡é›œåº¦
            st.info(
                f"**{t_func('prompt_type')}:** {analysis.get('prompt_type', 'unknown')} | "
                f"**{t_func('complexity_level')}:** {analysis.get('complexity_level', 'unknown')}"
            )

            # è©³ç´°åˆ†æï¼ˆå¯å±•é–‹ï¼‰
            with st.expander(t_func("view_details"), expanded=False):
                has_content = False

                if analysis.get('missing_elements'):
                    st.markdown(f"**{t_func('missing_elements')}:**")
                    for elem in analysis['missing_elements']:
                        st.markdown(f"- {elem}")
                    has_content = True

                if analysis.get('improvement_suggestions'):
                    st.markdown(f"**{t_func('improvement_suggestions')}:**")
                    for sugg in analysis['improvement_suggestions']:
                        st.markdown(f"- {sugg}")
                    has_content = True

                # å¦‚æœæ²’æœ‰å…·é«”å»ºè­°ä¸” analysis æœ‰å…§å®¹ï¼Œé¡¯ç¤ºå®Œæ•´åˆ†ææ•¸æ“š
                if not has_content and analysis:
                    st.json(analysis)


def render_questions_card(msg: Message, t_func: Callable[[str], str]):
    """
    æ¸²æŸ“æ”¹é€²å•é¡Œå¡ç‰‡

    Args:
        msg: å•é¡Œè¨Šæ¯ç‰©ä»¶
        t_func: ç¿»è­¯å‡½æ•¸
    """
    with st.chat_message("assistant", avatar="ğŸ’¡"):
        st.markdown("#### " + t_func("improvement_header"))

        if msg.questions_data:
            questions = msg.questions_data

            # æª¢æŸ¥æ­¤è¨Šæ¯æ˜¯å¦ç‚ºæœ€æ–°çš„å¾…å›ç­”å•é¡Œ
            session = st.session_state.current_session
            is_latest_questions = (
                session.pending_questions is not None and
                len(session.messages) > 0 and
                session.messages[-1].id == msg.id or
                (len(session.messages) > 1 and session.messages[-2].id == msg.id)
            )

            # ä½¿ç”¨è¡¨å–®æ”¶é›†æ‰€æœ‰å•é¡Œçš„å›ç­”
            with st.form(key=f"questions_form_{msg.id}"):
                responses = {}
                seen_types = set()  # è¿½è¹¤å·²è¦‹éçš„ typeï¼Œæª¢æ¸¬è¡çª

                for i, q in enumerate(questions):
                    question_text = q.get('question', '')
                    question_type = q.get('type', 'text')

                    # ä½¿ç”¨ question_type ä½œç‚º keyï¼ˆèˆ‡ PromptEvaluator.optimize_prompt çš„æœŸæœ›ä¸€è‡´ï¼‰
                    # è¨­è¨ˆå‡è¨­ï¼šYAML é…ç½®ç¢ºä¿æ¯å€‹å•é¡Œçš„ type å”¯ä¸€ï¼ˆrole, format, detail, scope, reasoningï¼‰
                    response_key = question_type

                    # æª¢æ¸¬ key è¡çªï¼ˆé˜²ç¦¦æ€§ç·¨ç¨‹ï¼‰
                    if response_key in seen_types:
                        # å¦‚æœæª¢æ¸¬åˆ°é‡è¤‡ï¼Œä½¿ç”¨ç´¢å¼•å¾Œç¶´
                        response_key = f"{question_type}_{i}"
                    seen_types.add(question_type)

                    # æ ¹æ“šå•é¡Œé¡å‹æ¸²æŸ“ä¸åŒçš„è¼¸å…¥å…ƒä»¶
                    if question_type == "reasoning" or q.get('input_type') == 'checkbox':
                        # Checkbox é¡å‹
                        responses[response_key] = st.checkbox(
                            question_text,
                            key=f"q_{msg.id}_{i}",
                            disabled=not is_latest_questions
                        )

                    elif q.get('input_type') == 'selectbox' and q.get('options'):
                        # ä¸‹æ‹‰é¸å–®é¡å‹
                        options = q['options']
                        labels = [opt['label'] for opt in options]
                        keys = [opt['key'] for opt in options]

                        # ç²å–é è¨­å€¼ç´¢å¼•ï¼ˆå¾ YAML é…ç½®çš„ default æ¬„ä½ï¼‰
                        default_key = q.get('default', None)
                        default_index = 0  # é è¨­ç‚ºç¬¬ä¸€å€‹é¸é …
                        if default_key and default_key in keys:
                            default_index = keys.index(default_key)

                        selected = st.selectbox(
                            question_text,
                            options=labels,
                            index=default_index,
                            key=f"q_{msg.id}_{i}",
                            disabled=not is_latest_questions
                        )

                        # æ‰¾åˆ°å°æ‡‰çš„ key
                        selected_index = labels.index(selected) if selected in labels else 0
                        responses[response_key] = keys[selected_index]

                    else:
                        # æ–‡å­—è¼¸å…¥é¡å‹
                        responses[response_key] = st.text_input(
                            question_text,
                            key=f"q_{msg.id}_{i}",
                            disabled=not is_latest_questions
                        )

                # æª¢æŸ¥æ˜¯å¦æ­£åœ¨è™•ç†ä¸­
                is_processing = st.session_state.get('is_processing', False)

                # æäº¤æŒ‰éˆ•ï¼ˆåªæœ‰æœ€æ–°çš„å•é¡Œå¯æäº¤ï¼Œä¸”æœªåœ¨è™•ç†ä¸­ï¼‰
                submitted = st.form_submit_button(
                    t_func("processing") if is_processing else t_func("generate_button"),
                    use_container_width=True,
                    disabled=not is_latest_questions or is_processing
                )

                if submitted and is_latest_questions and not is_processing:
                    # ä¿å­˜å›ç­”åˆ° session state
                    st.session_state.pending_responses = responses
                    st.session_state.trigger_optimization = True
                    st.rerun()


def render_optimization_card(msg: Message, t_func: Callable[[str], str]):
    """
    æ¸²æŸ“å„ªåŒ–çµæœå¡ç‰‡

    Args:
        msg: å„ªåŒ–è¨Šæ¯ç‰©ä»¶
        t_func: ç¿»è­¯å‡½æ•¸
    """
    with st.chat_message("assistant", avatar="âœ¨"):
        st.markdown("#### " + t_func("result_header"))

        if msg.optimization_data:
            result = msg.optimization_data

            # ç²å–åŸå§‹å’Œå„ªåŒ–å¾Œçš„æç¤º
            original_prompt = st.session_state.current_session.original_prompt
            enhanced_prompt = result.get("enhanced_prompt", "")

            # å°æ¯”å±•ç¤ºï¼ˆå·¦å³å…©æ¬„ï¼‰
            col1, col2 = st.columns(2)

            with col1:
                st.markdown(f"**ğŸ“„ {t_func('original_prompt')}**")
                st.text_area(
                    label="original",
                    value=original_prompt,
                    height=250,
                    disabled=True,
                    key=f"orig_{msg.id}",
                    label_visibility="collapsed"
                )

            with col2:
                st.markdown(f"**âœ¨ {t_func('enhanced_prompt')}**")
                st.text_area(
                    label="enhanced",
                    value=enhanced_prompt,
                    height=250,
                    key=f"enh_{msg.id}",
                    label_visibility="collapsed"
                )

            # æ”¹é€²èªªæ˜
            if result.get('improvements'):
                with st.expander(t_func("improvement_description"), expanded=True):
                    for improvement in result['improvements']:
                        st.markdown(f"- {improvement}")

            # æç¤ºï¼šå¯ç›´æ¥é¸æ“‡ä¸Šæ–¹æ–‡å­—è¤‡è£½
            st.info("ğŸ’¡ " + t_func("select_to_copy"))

            # æ“ä½œæŒ‰éˆ•ä½ˆå±€
            st.markdown("---")

            # ä¿å­˜æç¤ºæŒ‰éˆ•
            if st.button(t_func("save_prompt"), key=f"save_{msg.id}", type="primary", use_container_width=True):
                st.session_state.active_save_msg_id = msg.id
                st.rerun()

            # ä¿å­˜è¡¨å–®ï¼ˆåªé¡¯ç¤ºç•¶å‰é¸ä¸­çš„ï¼‰
            if st.session_state.get('active_save_msg_id') == msg.id:
                with st.expander(t_func("save_prompt"), expanded=True):
                    render_save_prompt_form(original_prompt, enhanced_prompt, msg.analysis_data, t_func, msg.id)



def render_save_prompt_form(original_prompt: str, optimized_prompt: str, analysis_scores: Optional[Dict], t_func: Callable[[str], str], msg_id: str):
    """
    æ¸²æŸ“ä¿å­˜æç¤ºè¡¨å–®

    Args:
        original_prompt: åŸå§‹æç¤º
        optimized_prompt: å„ªåŒ–å¾Œçš„æç¤º
        analysis_scores: åˆ†æè©•åˆ†
        t_func: ç¿»è­¯å‡½æ•¸
        msg_id: è¨Šæ¯ IDï¼ˆç”¨æ–¼å”¯ä¸€æ€§ï¼Œå¿…å¡«ï¼‰
    """
    save_name = st.text_input(t_func("save_name"), key=f"save_name_{msg_id}")
    save_tags = st.text_input(t_func("save_tags"), key=f"save_tags_{msg_id}")

    col_save, col_cancel = st.columns(2)

    with col_save:
        save_clicked = st.button(t_func("confirm"), key=f"confirm_save_{msg_id}", type="primary", use_container_width=True)

    with col_cancel:
        cancel_clicked = st.button(t_func("cancel"), key=f"cancel_save_{msg_id}", use_container_width=True)

    if cancel_clicked:
        # é—œé–‰ä¿å­˜è¡¨å–®
        st.session_state.active_save_msg_id = None
        st.rerun()

    if save_clicked:
        if save_name:
            try:
                # è™•ç†æ¨™ç±¤
                tags = [tag.strip() for tag in save_tags.split(",") if tag.strip()] if save_tags else []

                # ä¿å­˜åˆ°è³‡æ–™åº«
                prompt_id = st.session_state.prompt_db.save_prompt(
                    name=save_name,
                    original_prompt=original_prompt,
                    optimized_prompt=optimized_prompt,
                    analysis_scores=analysis_scores,
                    tags=tags,
                    language=st.session_state.language
                )

                # ä½¿å¿«å–å¤±æ•ˆ
                st.session_state.export_cache_key = str(time.time())

                # é—œé–‰ä¿å­˜è¡¨å–®
                st.session_state.active_save_msg_id = None

                st.success(t_func("save_success"))

                # æª¢æŸ¥æ˜¯å¦æœ‰å¾…è™•ç†çš„èªè¨€åˆ‡æ›
                pending_lang = st.session_state.pop('pending_language_switch', None)
                if pending_lang:
                    st.session_state.language = pending_lang
                    st.session_state.language_change_confirmed = True

                st.rerun()

            except Exception as e:
                st.error(f"{t_func('save_error')}: {str(e)}")
        else:
            st.warning(t_func("please_enter_name"))



def render_new_conversation_button(t_func: Callable[[str], str]):
    """
    æ¸²æŸ“ã€Œé–‹å§‹æ–°å°è©±ã€æŒ‰éˆ•

    Args:
        t_func: ç¿»è­¯å‡½æ•¸
    """
    if st.button("ğŸ”„ " + t_func("new_conversation"), use_container_width=True):
        # é‡ç½®æ‰€æœ‰å°è©±ç‹€æ…‹
        st.session_state.current_session = create_new_session()
        st.session_state.trigger_optimization = False
        st.session_state.pending_responses = {}
        st.session_state.active_save_msg_id = None
        st.session_state.is_processing = False
        st.rerun()


def get_conversation_ui_translations():
    """
    ç²å–å°è©±å¼ UI æ‰€éœ€çš„é¡å¤–ç¿»è­¯éµ

    Returns:
        ç¿»è­¯å­—å…¸ï¼ˆéœ€è¦åˆä½µåˆ° app.py çš„ translationsï¼‰
    """
    return {
        "zh_TW": {
            "chat_input_placeholder": "è¼¸å…¥æ‚¨è¦å„ªåŒ–çš„æç¤º...",
            "new_conversation": "é–‹å§‹æ–°å°è©±",
            "analysis_result": "æç¤ºåˆ†æçµæœ",
            "completeness_label": "å®Œæ•´æ€§",
            "clarity_label": "æ¸…æ™°åº¦",
            "structure_label": "çµæ§‹æ€§",
            "specificity_label": "å…·é«”æ€§",
            "complexity_level": "è¤‡é›œåº¦",
            "view_details": "æŸ¥çœ‹è©³ç´°åˆ†æ",
            "missing_elements": "ç¼ºå¤±å…ƒç´ ",
            "improvement_suggestions": "æ”¹é€²å»ºè­°",
            "please_answer_questions": "è«‹å›ç­”ä¸Šæ–¹çš„æ”¹é€²å•é¡Œ",
            "please_wait": "è«‹ç¨å€™...",
            "please_enter_name": "è«‹è¼¸å…¥æç¤ºåç¨±",
            "select_to_copy": "é¸æ“‡ä¸Šæ–¹ã€å„ªåŒ–å¾Œçš„æç¤ºã€æ–‡å­—æ¡†ä¸­çš„å…§å®¹å³å¯è¤‡è£½",
            "optimization_complete_hint": "âœ… å„ªåŒ–å®Œæˆï¼",
            "confirm": "ç¢ºå®š",
            "cancel": "å–æ¶ˆ",
            "loaded_prompt_label": "å·²è¼‰å…¥çš„æç¤ºï¼ˆå¯ç·¨è¼¯ï¼‰",
            "start_analysis": "é–‹å§‹åˆ†æ",
            "clear_loaded": "æ¸…é™¤"
        },
        "en": {
            "chat_input_placeholder": "Enter your prompt to optimize...",
            "new_conversation": "New Conversation",
            "analysis_result": "Prompt Analysis Result",
            "completeness_label": "Completeness",
            "clarity_label": "Clarity",
            "structure_label": "Structure",
            "specificity_label": "Specificity",
            "complexity_level": "Complexity",
            "view_details": "View Details",
            "missing_elements": "Missing Elements",
            "improvement_suggestions": "Improvement Suggestions",
            "please_answer_questions": "Please answer the improvement questions above",
            "please_wait": "Please wait...",
            "please_enter_name": "Please enter a name for the prompt",
            "select_to_copy": "Select text from the 'Enhanced Prompt' text area above to copy",
            "optimization_complete_hint": "âœ… Optimization complete!",
            "confirm": "Confirm",
            "cancel": "Cancel",
            "loaded_prompt_label": "Loaded Prompt (Editable)",
            "start_analysis": "Start Analysis",
            "clear_loaded": "Clear"
        },
        "ja": {
            "chat_input_placeholder": "æœ€é©åŒ–ã—ãŸã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
            "new_conversation": "æ–°ã—ã„ä¼šè©±",
            "analysis_result": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ†æçµæœ",
            "completeness_label": "å®Œå…¨æ€§",
            "clarity_label": "æ˜ç¢ºæ€§",
            "structure_label": "æ§‹é€ æ€§",
            "specificity_label": "å…·ä½“æ€§",
            "complexity_level": "è¤‡é›‘åº¦",
            "view_details": "è©³ç´°ã‚’è¡¨ç¤º",
            "missing_elements": "æ¬ è½è¦ç´ ",
            "improvement_suggestions": "æ”¹å–„ææ¡ˆ",
            "please_answer_questions": "ä¸Šè¨˜ã®æ”¹å–„è³ªå•ã«ç­”ãˆã¦ãã ã•ã„",
            "please_wait": "ãŠå¾…ã¡ãã ã•ã„...",
            "please_enter_name": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            "select_to_copy": "ä¸Šã®ã€Œæœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„",
            "optimization_complete_hint": "âœ… æœ€é©åŒ–å®Œäº†ï¼",
            "confirm": "ç¢ºå®š",
            "cancel": "ã‚­ãƒ£ãƒ³ã‚»ãƒ«",
            "loaded_prompt_label": "èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯èƒ½ï¼‰",
            "start_analysis": "åˆ†æã‚’é–‹å§‹",
            "clear_loaded": "ã‚¯ãƒªã‚¢"
        }
    }


def render_input_area_simple(session: ConversationSession, t_func: Callable[[str], str], create_llm_func: Callable[[], Any]):
    """
    ç°¡åŒ–ç‰ˆè¼¸å…¥å€åŸŸï¼ˆå–®æ¬¡å„ªåŒ–æµç¨‹ï¼šè¼¸å…¥ â†’ åˆ†æ â†’ å•é¡Œ â†’ å„ªåŒ– â†’ é‡æ–°é–‹å§‹ï¼‰

    Args:
        session: å°è©±æœƒè©±
        t_func: ç¿»è­¯å‡½æ•¸
        create_llm_func: å‰µå»º LLM å¯¦ä¾‹çš„å‡½æ•¸
    """
    # æª¢æŸ¥æ˜¯å¦æœ‰å¾…è™•ç†çš„å„ªåŒ–æ“ä½œ
    if st.session_state.get('trigger_optimization'):
        st.session_state.trigger_optimization = False
        st.session_state.is_processing = True
        responses = st.session_state.get('pending_responses', {})

        try:
            if responses:
                with st.spinner(t_func("processing")):
                    llm = create_llm_func()
                    flow = ConversationFlow(session, llm, st.session_state.language)
                    result = flow.handle_questions_response(responses)

                    optimization_result = result.get("optimization", {})
                    if "error" in optimization_result:
                        st.error(f"Error: {optimization_result.get('error')}")
                    else:
                        st.session_state.current_session = session
                        st.rerun()
        except Exception as e:
            logger.error("Error processing prompt", exc_info=True)
            st.error(f"An unexpected error occurred: {str(e)}")
        finally:
            st.session_state.is_processing = False

    # æª¢æŸ¥ç•¶å‰ç‹€æ…‹
    has_messages = len(session.messages) > 0
    has_optimization = session.last_optimization is not None
    has_pending_questions = session.pending_questions is not None and len(session.pending_questions) > 0

    # æª¢æŸ¥æ˜¯å¦æ­£åœ¨è™•ç†
    is_processing = st.session_state.get('is_processing', False)

    # å®šç¾©è™•ç†æç¤ºçš„å…±ç”¨é‚è¼¯
    def process_prompt(prompt_text: str):
        """è™•ç†æç¤ºåˆ†æçš„å…±ç”¨é‚è¼¯"""
        st.session_state.is_processing = True
        try:
            with st.spinner(t_func("processing")):
                llm = create_llm_func()
                flow = ConversationFlow(session, llm, st.session_state.language)
                result = flow.handle_initial_prompt(prompt_text)

                analysis_result = result.get("analysis", {})
                if "error" in analysis_result:
                    st.error(f"Error: {analysis_result.get('error')}")
                else:
                    st.session_state.current_session = session
                    st.rerun()
        except Exception as e:
            logger.error("Error processing prompt", exc_info=True)
            st.error(f"An unexpected error occurred: {str(e)}")
        finally:
            st.session_state.is_processing = False

    # æ¸²æŸ“è¼¸å…¥å€åŸŸ
    if not has_messages:
        st.write(t_func("initial_prompt_header"))


        # æª¢æŸ¥æ˜¯å¦æœ‰å¾æç¤ºè©åº«è¼‰å…¥çš„å…§å®¹
        if session.current_prompt and session.current_prompt.strip():
            # é¡¯ç¤ºå·²è¼‰å…¥çš„æç¤ºï¼ˆå¯ç·¨è¼¯ï¼‰
            loaded_prompt = st.text_area(
                t_func("loaded_prompt_label"),
                value=session.current_prompt,
                height=200,
                key="loaded_prompt_display"
            )

            # æä¾›é–‹å§‹åˆ†ææˆ–æ¸…é™¤é¸é …
            col1, col2 = st.columns(2)
            with col1:
                if st.button(t_func("start_analysis"), key="analyze_loaded", type="primary", use_container_width=True, disabled=is_processing):
                    # ä¿å­˜ç·¨è¼¯å¾Œçš„å…§å®¹åˆ° session
                    session.current_prompt = loaded_prompt
                    process_prompt(loaded_prompt)

            with col2:
                if st.button(t_func("clear_loaded"), key="clear_loaded", use_container_width=True):
                    session.current_prompt = ""
                    st.rerun()

        else:
            # æ²’æœ‰è¼‰å…¥å…§å®¹ï¼šé¡¯ç¤º chat_input
            user_input = st.chat_input(
                placeholder=t_func("chat_input_placeholder"),
                key="initial_chat_input",
                disabled=is_processing
            )

            if user_input:
                process_prompt(user_input)

    elif has_optimization:
        # å„ªåŒ–å®Œæˆï¼šé¡¯ç¤ºæç¤ºèˆ‡é‡æ–°é–‹å§‹æŒ‰éˆ•
        st.success(t_func("optimization_complete_hint"))

        if st.button("ğŸ”„ " + t_func("new_conversation"), key="restart_main_area", type="primary", use_container_width=True):
            # é‡ç½®æ‰€æœ‰å°è©±ç‹€æ…‹
            st.session_state.current_session = create_new_session()
            st.session_state.trigger_optimization = False
            st.session_state.pending_responses = {}
            st.session_state.active_save_msg_id = None
            st.session_state.is_processing = False
            st.rerun()

    elif has_pending_questions:
        # ç­‰å¾…ç”¨æˆ¶å›ç­”å•é¡Œï¼ˆå•é¡Œå·²åœ¨ render_questions_card ä¸­é¡¯ç¤ºï¼‰
        pass

    else:
        # å…¶ä»–ç‹€æ…‹
        st.info(t_func("please_wait"))
