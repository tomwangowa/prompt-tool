#!/usr/bin/env python3
"""
å°è©±æµç¨‹æ§åˆ¶æ¨¡çµ„
ç®¡ç†å°è©±å¼ UI çš„ç‹€æ…‹æ©Ÿå’Œæµç¨‹é‚è¼¯
"""

from typing import Dict, Any, Optional
import logging

from conversation_types import (
    ConversationSession,
    Message,
    MessageRole,
    MessageType,
    ConversationState
)
from prompt_eval import PromptEvaluator
from llm_invoker import ParameterPresets

logger = logging.getLogger(__name__)


class ConversationFlow:
    """å°è©±æµç¨‹æ§åˆ¶å™¨"""

    # éŒ¯èª¤è¨Šæ¯ç¿»è­¯
    ERROR_MESSAGES = {
        "zh_TW": {
            "analysis_error": "æŠ±æ­‰ï¼Œåˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error}",
            "questions_error": "æŠ±æ­‰ï¼Œç”Ÿæˆæ”¹é€²å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error}",
            "modification_error": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„ä¿®æ”¹è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error}",
            "conversation_error": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error}"
        },
        "en": {
            "analysis_error": "Sorry, an error occurred during analysis: {error}",
            "questions_error": "Sorry, an error occurred while generating questions: {error}",
            "modification_error": "Sorry, an error occurred while processing your modification request: {error}",
            "conversation_error": "Sorry, an error occurred while processing your question: {error}"
        },
        "ja": {
            "analysis_error": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{error}",
            "questions_error": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚è³ªå•ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{error}",
            "modification_error": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ä¿®æ­£ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{error}",
            "conversation_error": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã”è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{error}"
        }
    }

    # LLM Prompt æ¨¡æ¿ç¿»è­¯
    PROMPT_TEMPLATES = {
        "zh_TW": {
            "modification": """åŸºæ–¼ä»¥ä¸‹ç•¶å‰æç¤ºé€²è¡Œèª¿æ•´ï¼š

<current_prompt>
{current_prompt}
</current_prompt>

<user_request>
{user_input}
</user_request>

è«‹æ ¹æ“šç”¨æˆ¶è¦æ±‚èª¿æ•´æç¤ºï¼Œä¿æŒå…¶ä»–éƒ¨åˆ†ä¸è®Šã€‚åªè¼¸å‡ºèª¿æ•´å¾Œçš„å®Œæ•´æç¤ºã€‚""",
            "conversation": """å°è©±ä¸Šä¸‹æ–‡ï¼š
{context}

ç•¶å‰å„ªåŒ–çš„æç¤ºï¼š
<current_prompt>
{current_prompt}
</current_prompt>

ç”¨æˆ¶å•é¡Œï¼š
<user_question>
{user_input}
</user_question>

è«‹æ ¹æ“šå°è©±ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚"""
        },
        "en": {
            "modification": """Adjust based on the current prompt:

<current_prompt>
{current_prompt}
</current_prompt>

<user_request>
{user_input}
</user_request>

Please adjust the prompt according to the user's request, keeping other parts unchanged. Output only the complete adjusted prompt.""",
            "conversation": """Conversation context:
{context}

Current optimized prompt:
<current_prompt>
{current_prompt}
</current_prompt>

User question:
<user_question>
{user_input}
</user_question>

Please answer the user's question based on the conversation context."""
        },
        "ja": {
            "modification": """ä»¥ä¸‹ã®ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦èª¿æ•´ã—ã¦ãã ã•ã„ï¼š

<current_prompt>
{current_prompt}
</current_prompt>

<user_request>
{user_input}
</user_request>

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¾“ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿æ•´ã—ã€ä»–ã®éƒ¨åˆ†ã¯å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚èª¿æ•´å¾Œã®å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚""",
            "conversation": """ä¼šè©±ã®æ–‡è„ˆï¼š
{context}

ç¾åœ¨ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼š
<current_prompt>
{current_prompt}
</current_prompt>

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ï¼š
<user_question>
{user_input}
</user_question>

ä¼šè©±ã®æ–‡è„ˆã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"""
        }
    }

    def __init__(self, session: ConversationSession, llm_instance: Any, language: str = "zh_TW"):
        """
        åˆå§‹åŒ–å°è©±æµç¨‹æ§åˆ¶å™¨

        Args:
            session: å°è©±æœƒè©±
            llm_instance: LLM å¯¦ä¾‹
            language: èªè¨€ä»£ç¢¼
        """
        self.session = session
        self.llm = llm_instance
        self.language = language
        self.evaluator = PromptEvaluator(llm_instance=llm_instance)
        self.state = ConversationState.IDLE

    def _get_error_message(self, key: str, error: str) -> str:
        """ç²å–æœ¬åœ°åŒ–çš„éŒ¯èª¤è¨Šæ¯"""
        messages = self.ERROR_MESSAGES.get(self.language, self.ERROR_MESSAGES["zh_TW"])
        return messages.get(key, "Error: {error}").format(error=error)

    def _sanitize_input(self, text: str) -> str:
        """é˜²æ­¢ Prompt Injectionï¼ˆè½‰ç¾© XML æ¨™ç±¤ï¼‰"""
        if not text:
            return ""
        return text.replace("<", "&lt;").replace(">", "&gt;")

    def handle_initial_prompt(self, prompt: str) -> Dict[str, Any]:
        """
        è™•ç†åˆå§‹ prompt è¼¸å…¥

        Args:
            prompt: ç”¨æˆ¶è¼¸å…¥çš„æç¤º

        Returns:
            åŒ…å«åˆ†æå’Œå•é¡Œçš„çµæœå­—å…¸
        """
        # è¨˜éŒ„ç”¨æˆ¶è¨Šæ¯
        user_msg = self.session.add_message(
            role=MessageRole.USER,
            msg_type=MessageType.TEXT,
            content=prompt
        )

        # æ›´æ–°æœƒè©±çš„ prompt
        self.session.original_prompt = prompt
        self.session.current_prompt = prompt

        # è‡ªå‹•è§¸ç™¼åˆ†æ
        self.state = ConversationState.ANALYZING
        analysis_result = self.analyze_prompt(prompt)

        # æª¢æŸ¥åˆ†ææ˜¯å¦å¤±æ•—
        if "error" in analysis_result:
            self.state = ConversationState.IDLE
            return {
                "user_message": user_msg,
                "analysis": analysis_result,
                "questions": None,
                "state": self.state
            }

        # è‡ªå‹•ç”Ÿæˆæ”¹é€²å•é¡Œ
        self.state = ConversationState.AWAITING_QUESTIONS
        questions_result = self.generate_questions()

        # æª¢æŸ¥å•é¡Œç”Ÿæˆæ˜¯å¦å¤±æ•—
        if "error" in questions_result:
            return {
                "user_message": user_msg,
                "analysis": analysis_result,
                "questions": questions_result,
                "state": self.state
            }

        return {
            "user_message": user_msg,
            "analysis": analysis_result,
            "questions": questions_result,
            "state": self.state
        }

    def analyze_prompt(self, prompt: str) -> Dict[str, Any]:
        """
        åŸ·è¡Œ prompt åˆ†æ

        Args:
            prompt: è¦åˆ†æçš„æç¤º

        Returns:
            åˆ†æçµæœå­—å…¸
        """
        try:
            # èª¿ç”¨ PromptEvaluator é€²è¡Œåˆ†æ
            analysis = self.evaluator.analyze_prompt(prompt, self.language)

            # æ ¼å¼åŒ–åˆ†æå…§å®¹
            analysis_content = self._format_analysis_content(analysis)

            # æ·»åŠ åˆ†æçµæœè¨Šæ¯
            analysis_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.ANALYSIS,
                content=analysis_content,
                analysis_data=analysis
            )

            # ä¿å­˜åˆ†æçµæœ
            self.session.last_analysis = analysis

            return {
                "message": analysis_msg,
                "analysis": analysis
            }

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¿”å›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
            logger.error("Error analyzing prompt", exc_info=True)
            error_msg = self._get_error_message("analysis_error", str(e))
            error_message = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=error_msg
            )
            return {
                "message": error_message,
                "error": str(e)
            }

    def generate_questions(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ”¹é€²å•é¡Œ

        Returns:
            å•é¡Œçµæœå­—å…¸
        """
        if not self.session.last_analysis:
            raise ValueError("å¿…é ˆå…ˆåŸ·è¡Œåˆ†ææ‰èƒ½ç”Ÿæˆå•é¡Œ")

        try:
            # èª¿ç”¨ PromptEvaluator ç”Ÿæˆå•é¡Œ
            questions = self.evaluator.generate_questions(
                self.session.last_analysis,
                self.language
            )

            # æ ¼å¼åŒ–å•é¡Œå…§å®¹
            questions_content = self._format_questions_content(questions)

            # æ·»åŠ å•é¡Œè¨Šæ¯
            questions_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.QUESTIONS,
                content=questions_content,
                questions_data=questions
            )

            # ä¿å­˜å¾…å›ç­”çš„å•é¡Œ
            self.session.pending_questions = questions

            return {
                "message": questions_msg,
                "questions": questions
            }

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¿”å›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
            logger.error("Error generating questions", exc_info=True)
            error_msg = self._get_error_message("questions_error", str(e))
            error_message = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=error_msg
            )
            return {
                "message": error_message,
                "error": str(e)
            }

    def handle_questions_response(self, responses: Dict[str, Any]) -> Dict[str, Any]:
        """
        è™•ç†ç”¨æˆ¶å°æ”¹é€²å•é¡Œçš„å›ç­”

        Args:
            responses: ç”¨æˆ¶å›ç­”å­—å…¸

        Returns:
            å„ªåŒ–çµæœå­—å…¸
        """
        # è¨˜éŒ„ç”¨æˆ¶å›ç­”
        responses_content = self._format_responses_content(responses)
        user_msg = self.session.add_message(
            role=MessageRole.USER,
            msg_type=MessageType.TEXT,
            content=responses_content,
            metadata={"responses": responses}
        )

        # ä¿å­˜å›ç­”
        self.session.question_answers = responses

        # åŸ·è¡Œå„ªåŒ–
        self.state = ConversationState.OPTIMIZING
        optimization_result = self.optimize_prompt(responses)

        self.state = ConversationState.COMPLETED

        return {
            "user_message": user_msg,
            "optimization": optimization_result,
            "state": self.state
        }

    def optimize_prompt(self, responses: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸ·è¡Œ prompt å„ªåŒ–

        Args:
            responses: ç”¨æˆ¶å›ç­”å­—å…¸

        Returns:
            å„ªåŒ–çµæœå­—å…¸
        """
        if not self.session.last_analysis:
            raise ValueError("å¿…é ˆå…ˆåŸ·è¡Œåˆ†ææ‰èƒ½å„ªåŒ–")

        try:
            # èª¿ç”¨ PromptEvaluator é€²è¡Œå„ªåŒ–
            result = self.evaluator.optimize_prompt(
                self.session.current_prompt,
                responses,
                self.session.last_analysis,
                self.language
            )

            # æ·»åŠ å„ªåŒ–çµæœè¨Šæ¯
            optimization_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.OPTIMIZATION,
                content=result["enhanced_prompt"],
                optimization_data=result
            )

            # æ›´æ–°æœƒè©±ç‹€æ…‹
            self.session.last_optimization = result
            self.session.current_prompt = result["enhanced_prompt"]
            self.session.iteration_count += 1

            return {
                "message": optimization_msg,
                "result": result
            }

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¿”å›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯ï¼ˆä½¿ç”¨ conversation_error ä½œç‚ºé€šç”¨éŒ¯èª¤ï¼‰
            logger.error("Error optimizing prompt", exc_info=True)
            error_msg = self._get_error_message("conversation_error", str(e))
            error_message = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=error_msg
            )
            return {
                "message": error_message,
                "error": str(e)
            }

    def handle_followup_message(self, user_input: str) -> Dict[str, Any]:
        """
        è™•ç†å„ªåŒ–å®Œæˆå¾Œçš„æŒçºŒå°è©±

        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥

        Returns:
            è™•ç†çµæœå­—å…¸
        """
        # è¨˜éŒ„ç”¨æˆ¶è¨Šæ¯
        user_msg = self.session.add_message(
            role=MessageRole.USER,
            msg_type=MessageType.TEXT,
            content=user_input
        )

        # æ ¹æ“šç”¨æˆ¶æ„åœ–æ±ºå®šä¸‹ä¸€æ­¥
        intent = self._classify_user_intent(user_input)

        if intent == "iterate":
            # ç”¨æˆ¶æƒ³è¦å†æ¬¡å„ªåŒ–
            return self.handle_initial_prompt(self.session.current_prompt)
        elif intent == "modify":
            # ç”¨æˆ¶æƒ³è¦èª¿æ•´æŸå€‹æ–¹é¢
            return self._handle_modification_request(user_input)
        else:
            # ä¸€èˆ¬æ€§å°è©±
            return self._handle_general_conversation(user_input)

    def _classify_user_intent(self, user_input: str) -> str:
        """
        åˆ†é¡ç”¨æˆ¶æ„åœ–ï¼ˆä½¿ç”¨é—œéµå­—åŒ¹é…ï¼‰

        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥

        Returns:
            æ„åœ–é¡å‹ï¼šiterate, modify, general
        """
        input_lower = user_input.lower()

        # è¿­ä»£é—œéµå­—ï¼ˆå„ªå…ˆæª¢æŸ¥ï¼Œè¼ƒç‚ºæ˜ç¢ºï¼‰
        iterate_keywords = ["å†æ¬¡å„ªåŒ–", "ç¹¼çºŒå„ªåŒ–", "optimize again", "iterate", "ã‚‚ã†ä¸€åº¦æœ€é©åŒ–"]
        if any(kw in input_lower for kw in iterate_keywords):
            return "iterate"

        # ä¿®æ”¹é—œéµå­—
        modify_keywords = ["ä¿®æ”¹", "èª¿æ•´", "æ”¹ä¸€ä¸‹", "modify", "adjust", "change", "å¤‰æ›´"]
        if any(kw in input_lower for kw in modify_keywords):
            return "modify"

        return "general"

    def _handle_modification_request(self, user_input: str) -> Dict[str, Any]:
        """
        è™•ç†ä¿®æ”¹è«‹æ±‚

        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥

        Returns:
            è™•ç†çµæœå­—å…¸
        """
        # ä½¿ç”¨æœ¬åœ°åŒ–çš„æç¤ºæ¨¡æ¿ï¼Œä¸¦é˜²æ­¢ Prompt Injection
        templates = self.PROMPT_TEMPLATES.get(self.language, self.PROMPT_TEMPLATES["zh_TW"])
        modification_prompt = templates["modification"].format(
            current_prompt=self._sanitize_input(self.session.current_prompt),
            user_input=self._sanitize_input(user_input)
        )

        try:
            # ä½¿ç”¨ç²¾ç¢ºåƒæ•¸é è¨­ï¼ˆé©åˆä¿®æ”¹ä»»å‹™ï¼‰
            precise_params = ParameterPresets.get_preset("ç²¾ç¢º")
            # ç§»é™¤ descriptionï¼ˆinvoke ä¸æ¥å—æ­¤åƒæ•¸ï¼‰
            llm_params = {k: v for k, v in precise_params.items() if k != 'description'}
            result = self.llm.invoke(
                prompt=modification_prompt,
                **llm_params
            )

            modified_prompt = result["content"].strip()

            # æ·»åŠ  AI å›æ‡‰
            response_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=modified_prompt
            )

            # æ›´æ–°ç•¶å‰æç¤º
            self.session.current_prompt = modified_prompt

            return {
                "message": response_msg,
                "modified_prompt": modified_prompt
            }

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¿”å›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
            logger.error("Error handling modification request", exc_info=True)
            error_msg = self._get_error_message("modification_error", str(e))
            response_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=error_msg
            )
            return {
                "message": response_msg,
                "error": str(e)
            }

    def _handle_general_conversation(self, user_input: str) -> Dict[str, Any]:
        """
        è™•ç†ä¸€èˆ¬æ€§å°è©±

        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥

        Returns:
            è™•ç†çµæœå­—å…¸
        """
        # æ§‹å»ºå°è©±ä¸Šä¸‹æ–‡
        context = self._build_conversation_context()

        # ä½¿ç”¨æœ¬åœ°åŒ–çš„æç¤ºæ¨¡æ¿ï¼Œä¸¦é˜²æ­¢ Prompt Injection
        templates = self.PROMPT_TEMPLATES.get(self.language, self.PROMPT_TEMPLATES["zh_TW"])
        conversation_prompt = templates["conversation"].format(
            context=context,
            current_prompt=self._sanitize_input(self.session.current_prompt),
            user_input=self._sanitize_input(user_input)
        )

        try:
            # ä½¿ç”¨å¹³è¡¡åƒæ•¸é è¨­ï¼ˆé©åˆä¸€èˆ¬å°è©±ï¼‰
            balanced_params = ParameterPresets.get_preset("å¹³è¡¡")
            # ç§»é™¤ descriptionï¼ˆinvoke ä¸æ¥å—æ­¤åƒæ•¸ï¼‰
            llm_params = {k: v for k, v in balanced_params.items() if k != 'description'}
            result = self.llm.invoke(
                prompt=conversation_prompt,
                **llm_params
            )

            response_content = result["content"].strip()

            # æ·»åŠ  AI å›æ‡‰
            response_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=response_content
            )

            return {
                "message": response_msg,
                "response": response_content
            }

        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¿”å›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
            logger.error("Error handling general conversation", exc_info=True)
            error_msg = self._get_error_message("conversation_error", str(e))
            response_msg = self.session.add_message(
                role=MessageRole.ASSISTANT,
                msg_type=MessageType.TEXT,
                content=error_msg
            )
            return {
                "message": response_msg,
                "error": str(e)
            }

    def _build_conversation_context(self) -> str:
        """
        æ§‹å»ºå°è©±ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘çš„è¨Šæ¯ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„å°è©±ä¸Šä¸‹æ–‡
        """
        # ç²å–æœ€è¿‘ 5 æ¢è¨Šæ¯
        recent_messages = self.session.messages[-5:] if len(self.session.messages) > 5 else self.session.messages

        context_lines = []
        for msg in recent_messages:
            role_label = "ç”¨æˆ¶" if msg.role == MessageRole.USER else "AI åŠ©æ‰‹"
            # ä¸æˆªæ–·å…§å®¹ - Prompt Engineering å·¥å…·éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡
            # Token ç®¡ç†ç”± LLM invoke å±¤è™•ç†
            context_lines.append(f"{role_label}: {msg.content}")

        return "\n".join(context_lines)

    def _format_analysis_content(self, analysis: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–åˆ†æçµæœå…§å®¹

        Args:
            analysis: åˆ†æçµæœå­—å…¸

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å…§å®¹
        """
        content_parts = [
            "ğŸ“Š æç¤ºåˆ†æçµæœ",
            "",
            f"å®Œæ•´æ€§ï¼š{analysis.get('completeness_score', 0)}/10",
            f"æ¸…æ™°åº¦ï¼š{analysis.get('clarity_score', 0)}/10",
            f"çµæ§‹æ€§ï¼š{analysis.get('structure_score', 0)}/10",
            f"å…·é«”æ€§ï¼š{analysis.get('specificity_score', 0)}/10",
            "",
            f"æç¤ºé¡å‹ï¼š{analysis.get('prompt_type', 'æœªçŸ¥')}",
            f"è¤‡é›œåº¦ï¼š{analysis.get('complexity_level', 'æœªçŸ¥')}"
        ]

        return "\n".join(content_parts)

    def _format_questions_content(self, questions: list) -> str:
        """
        æ ¼å¼åŒ–å•é¡Œå…§å®¹

        Args:
            questions: å•é¡Œåˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å…§å®¹
        """
        if not questions:
            return "æ²’æœ‰éœ€è¦å›ç­”çš„å•é¡Œã€‚"

        content_parts = ["ğŸ’¡ è®“æˆ‘å€‘ä¸€èµ·æ”¹é€²æ‚¨çš„æç¤º", ""]
        for i, q in enumerate(questions, 1):
            content_parts.append(f"{i}. {q.get('question', '')}")

        return "\n".join(content_parts)

    def _format_responses_content(self, responses: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–ç”¨æˆ¶å›ç­”å…§å®¹

        Args:
            responses: å›ç­”å­—å…¸

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å…§å®¹
        """
        content_parts = ["æˆ‘çš„å›ç­”ï¼š", ""]
        for key, value in responses.items():
            content_parts.append(f"- {key}: {value}")

        return "\n".join(content_parts)

    def reset_conversation(self):
        """é‡ç½®å°è©±ç‹€æ…‹"""
        self.session.clear_messages()
        self.session.current_prompt = ""
        self.session.original_prompt = ""
        self.session.last_analysis = None
        self.session.last_optimization = None
        self.session.pending_questions = None
        self.session.question_answers = {}
        self.session.iteration_count = 0
        self.state = ConversationState.IDLE

    def can_optimize(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥åŸ·è¡Œå„ªåŒ–"""
        return (
            self.session.last_analysis is not None and
            self.session.question_answers is not None and
            len(self.session.question_answers) > 0
        )

    def get_state_summary(self) -> Dict[str, Any]:
        """ç²å–ç•¶å‰ç‹€æ…‹æ‘˜è¦"""
        return {
            "state": self.state.value,
            "message_count": len(self.session.messages),
            "iteration_count": self.session.iteration_count,
            "has_analysis": self.session.last_analysis is not None,
            "has_optimization": self.session.last_optimization is not None,
            "pending_questions_count": len(self.session.pending_questions) if self.session.pending_questions else 0
        }
